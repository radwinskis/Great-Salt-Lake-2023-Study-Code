{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from scipy import stats\n",
    "from scipy.interpolate import UnivariateSpline, LSQUnivariateSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lOAD HYPSOMETRY DATA AND CREATE DATAFRAME FOR EACH COLUMN\n",
    "### ENSURE TO EDIT PATHS TO FILES ###\n",
    "src = 'LOCAL PATH TO GSL_Area_vs_Elevation_dataframe.csv'\n",
    "df = pd.read_csv(src, dtype='float')\n",
    "stage = df.iloc[4:, 0:1]\n",
    "total = df.iloc[4:, 1:2]\n",
    "SA_FB = df.iloc[4:, 2:3]\n",
    "NA_BRB = df.iloc[4:, 3:4]\n",
    "NA_SA = df.iloc[4:, 4:5]\n",
    "SA = df.iloc[4:, 5:6]\n",
    "NA = df.iloc[4:, 6:7]\n",
    "BRB = NA_BRB['NA + BRB']-NA['North Arm Sum']\n",
    "\n",
    "# DEFINE KNOTS\n",
    "NA_knots = [4169, 4171, 4173, 4178, 4183, 4188, 4194, 4200, 4201, 4203, 4205, 4207, 4209, 4211, 4214]\n",
    "\n",
    "\n",
    "#SET UP INTERPOLATION\n",
    "NA_intrp = LSQUnivariateSpline(stage.to_numpy().T[0], NA.to_numpy().T[0], np.array(NA_knots))\n",
    "\n",
    "SA_intrp = LSQUnivariateSpline(stage.to_numpy().T[0], SA_FB.to_numpy().T[0], np.array(NA_knots))\n",
    "\n",
    "BRB_intrp = LSQUnivariateSpline(stage.to_numpy().T[0], BRB.to_numpy(), np.array(NA_knots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD csv of elevation data for North and/or South Arms#\n",
    "# example filenames on github: 'GSL_NA_Elevation_Data_CSV.csv' and'GSL_SA_Elevation_Data_CSV.csv'\n",
    "NA_elevations = pd.read_csv('LOCAL PATH TO GSL_NA_Elevation_Data_CSV.csv')\n",
    "NA_elevations['Dates'] = pd.to_datetime(NA_elevations['Date'])\n",
    "SA_elevations = pd.read_csv('LOCAL PATH TO GSL_SA_Elevation_Data_CSV.csv')\n",
    "SA_elevations['Dates'] = pd.to_datetime(SA_elevations['Date'])\n",
    "\n",
    "# Input elevation time series data to output water surface area time series#\n",
    "NA_area_TS = pd.DataFrame(NA_intrp(NA_elevations['Elevation (ft)'][-650-240:-1])) #you can set the range for which to calculate surface area - in this case I went back to the 1980's to present from the elevation data\n",
    "NA_dates_TS = pd.to_datetime(NA_elevations['Date'][-650-240:-1])\n",
    "\n",
    "SA_area_TS = pd.DataFrame(SA_intrp(SA_elevations['Elevation (ft)'][-650-439:-1])) #you can set the range for which to calculate surface area - in this case I went back to the 1980's to present from the elevation data\n",
    "SA_dates_TS = pd.to_datetime(SA_elevations['Date'][-650-439:-1])\n",
    "\n",
    "BRB_area_TS = pd.DataFrame(BRB_intrp(SA_elevations['Elevation (ft)'][-650-439:-1])) #you can set the range for which to calculate surface area - in this case I went back to the 1980's to present from the elevation data\n",
    "BRB_dates_TS = pd.to_datetime(SA_elevations['Date'][-650-439:-1])\n",
    "\n",
    "#Using the above function to model exposed lakebed area #\n",
    "NA_intrp_shoreland = pd.DataFrame(2211536846 - 169059598 - NA_area_TS)\n",
    "SA_intrp_shoreland = pd.DataFrame(2844393367.45774 - SA_area_TS)\n",
    "BRB_intrp_shoreland = pd.DataFrame(1154526904 - BRB_area_TS)\n",
    "\n",
    "#voila, now you have dataframes of modelled surface areas from an input time series dataset of lake elevations\n",
    "# Now go plot and analyze!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee_2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
